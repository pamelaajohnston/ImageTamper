{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-----------------\n",
    "Got these results from a bunch of classifiers and this is to analyse them.\n",
    "-----------------\n",
    "\n",
    "The csv data that was fed to the classifiers was \"compression features\" from the D'avino dataset (by my CNNs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>data</th>\n",
       "      <th>classifier</th>\n",
       "      <th>balancing</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>total f1</th>\n",
       "      <th>imb ratio</th>\n",
       "      <th>f1 (auth)</th>\n",
       "      <th>f1 (tamp)</th>\n",
       "      <th>f1 mine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01_TANK_f</td>\n",
       "      <td>d_i_k_q_</td>\n",
       "      <td>NB</td>\n",
       "      <td>-</td>\n",
       "      <td>762.75</td>\n",
       "      <td>8484.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>0.129821</td>\n",
       "      <td>0.233035</td>\n",
       "      <td>0.054396</td>\n",
       "      <td>0.152401</td>\n",
       "      <td>0.106004</td>\n",
       "      <td>0.364408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01_TANK_f</td>\n",
       "      <td>d_i_k_q_</td>\n",
       "      <td>NB</td>\n",
       "      <td>ro</td>\n",
       "      <td>762.75</td>\n",
       "      <td>8484.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>0.129821</td>\n",
       "      <td>0.233035</td>\n",
       "      <td>0.054396</td>\n",
       "      <td>0.152401</td>\n",
       "      <td>0.106004</td>\n",
       "      <td>0.364408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01_TANK_f</td>\n",
       "      <td>d_i_k_q_</td>\n",
       "      <td>NB</td>\n",
       "      <td>ru</td>\n",
       "      <td>762.75</td>\n",
       "      <td>8484.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>0.129821</td>\n",
       "      <td>0.233035</td>\n",
       "      <td>0.054396</td>\n",
       "      <td>0.152401</td>\n",
       "      <td>0.106004</td>\n",
       "      <td>0.364408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01_TANK_f</td>\n",
       "      <td>d_i_k_q_</td>\n",
       "      <td>NB</td>\n",
       "      <td>s</td>\n",
       "      <td>762.75</td>\n",
       "      <td>8484.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>0.129821</td>\n",
       "      <td>0.233035</td>\n",
       "      <td>0.054396</td>\n",
       "      <td>0.152401</td>\n",
       "      <td>0.106004</td>\n",
       "      <td>0.364408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01_TANK_f</td>\n",
       "      <td>d_i_k_q_</td>\n",
       "      <td>dt</td>\n",
       "      <td>-</td>\n",
       "      <td>9247.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>503.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.948410</td>\n",
       "      <td>0.973522</td>\n",
       "      <td>0.054396</td>\n",
       "      <td>0.973522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        File      data classifier balancing       TN       FP     FN     TP  \\\n",
       "0  01_TANK_f  d_i_k_q_         NB         -   762.75  8484.25    0.0  503.0   \n",
       "1  01_TANK_f  d_i_k_q_         NB        ro   762.75  8484.25    0.0  503.0   \n",
       "2  01_TANK_f  d_i_k_q_         NB        ru   762.75  8484.25    0.0  503.0   \n",
       "3  01_TANK_f  d_i_k_q_         NB         s   762.75  8484.25    0.0  503.0   \n",
       "4  01_TANK_f  d_i_k_q_         dt         -  9247.00     0.00  503.0    0.0   \n",
       "\n",
       "   accuracy  total f1  imb ratio  f1 (auth)  f1 (tamp)   f1 mine  \n",
       "0  0.129821  0.233035   0.054396   0.152401   0.106004  0.364408  \n",
       "1  0.129821  0.233035   0.054396   0.152401   0.106004  0.364408  \n",
       "2  0.129821  0.233035   0.054396   0.152401   0.106004  0.364408  \n",
       "3  0.129821  0.233035   0.054396   0.152401   0.106004  0.364408  \n",
       "4  0.948410  0.973522   0.054396   0.973522   0.000000  0.973522  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('output_all_Davino_individually.csv')\n",
    "df = df.sort_values(by=[\"File\", \"data\", \"classifier\", \"balancing\"], ascending=True)\n",
    "df = df.groupby([\"File\", \"data\", \"classifier\", \"balancing\"], as_index=False).mean()\n",
    "df = df.drop('stratification', 1)\n",
    "\n",
    "\n",
    "#df['num tampered'] = df['TP'] + df ['FN']\n",
    "#df['num auth'] = df['TN'] + df['FP']\n",
    "df['imb ratio'] = (df['TP'] + df ['FN'])/(df['TN'] + df['FP'])\n",
    "\n",
    "df['f1 (auth)'] = 2 * df[\"TN\"] / ((2*df[\"TN\"]) + df[\"FP\"] + df[\"FN\"])\n",
    "df['f1 (tamp)'] = 2 * df[\"TP\"] / ((2*df[\"TP\"]) + df[\"FN\"] + df[\"FP\"])\n",
    "df['f1 mine'] = (2 * df['f1 (tamp)']) + df['f1 (auth)']\n",
    "\n",
    "# and now, \"get rid\" of stratification\n",
    "\n",
    "\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 imb ratio  f1 (tamp)\n",
      "File                                 \n",
      "07_UFO_f          0.001309   0.005937\n",
      "03_CAT_f          0.005261   0.023818\n",
      "09_GIRL_f         0.013954   0.045805\n",
      "05_HEN_f          0.038579   0.137185\n",
      "08_TREE_f         0.043599   0.273493\n",
      "01_TANK_f         0.054396   0.152216\n",
      "04_HELICOPTER_f   0.058388   0.174183\n",
      "10_DOG_f          0.062655   0.257333\n",
      "06_LION_f         0.078516   0.412789\n",
      "02_MAN_f          0.107624   0.291717\n",
      "\n",
      "\n",
      "\n",
      "The least imbalanced file is 02_MAN_f\n",
      "The most imbalanced file is 07_UFO_f\n",
      "The *easiest* sequence is 06_LION_f\n",
      "The *hardest* sequence is 07_UFO_f\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEZCAYAAABWwhjiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119bf0610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#myloc = df.loc[(df['File'] == '01_TANK_f') & (df['data']=='d_i_k_q_') & (df['balancing']=='-') & (df['classifier'] == 'NB')]\n",
    "df1 = df.groupby(['File']).mean()\n",
    "myloc = df1.sort_values(by=[\"imb ratio\"], ascending=True)\n",
    "print(myloc[['imb ratio', 'f1 (tamp)']])\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "plt.plot(myloc['imb ratio'], myloc['f1 (tamp)'])\n",
    "plt.title(\"Imbalance Ratio vs f1 (tamp)\")\n",
    "plt.xlabel(\"imb ratio\")\n",
    "plt.ylabel(\"f1 (tamp)\")\n",
    "\n",
    "print(\"The least imbalanced file is {}\".format(myloc['imb ratio'].idxmax()))\n",
    "print(\"The most imbalanced file is {}\".format(myloc['imb ratio'].idxmin()))\n",
    "print(\"The *easiest* sequence is {}\".format(myloc['f1 (tamp)'].idxmax()))\n",
    "print(\"The *hardest* sequence is {}\".format(myloc['f1 (tamp)'].idxmin()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    960.000000\n",
       "mean       0.177448\n",
       "std        0.154654\n",
       "min        0.000000\n",
       "25%        0.022525\n",
       "50%        0.157307\n",
       "75%        0.278437\n",
       "max        0.648087\n",
       "Name: f1 (tamp), dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['f1 (tamp)'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           f1 (tamp)  f1 (auth)\n",
      "balancing                      \n",
      "-           0.147760   0.919857\n",
      "ro          0.190193   0.809977\n",
      "ru          0.182948   0.793707\n",
      "s           0.188889   0.813407\n",
      "\n",
      "\n",
      "The best method of balancing for the minority class is ro\n",
      "The worst method of balancing for the minority class is -\n",
      "The best method of balancing for the majority class is -\n",
      "The worst method of balancing for the majority class is ru\n",
      "The best method of balancing for the both classes is -\n",
      "The worst method of balancing for the both classes is ru\n",
      "The best method of balancing for the accuracy is -\n",
      "The worst method of balancing for the accuracy is ru\n"
     ]
    }
   ],
   "source": [
    "df2 = df.groupby(['balancing']).mean()\n",
    "myloc = df2\n",
    "print(myloc[['f1 (tamp)', 'f1 (auth)']])\n",
    "print('\\n')\n",
    "\n",
    "assessThese = ['f1 (tamp)', 'f1 (auth)', 'total f1', 'accuracy']\n",
    "assessTheseMeanings = ['minority class', 'majority class', 'both classes', 'accuracy']\n",
    "for i, aThing in enumerate(assessThese):\n",
    "    print(\"The best method of balancing for the {} is {}\".format(assessTheseMeanings[i], myloc[aThing].idxmax()))\n",
    "    print(\"The worst method of balancing for the {} is {}\".format(assessTheseMeanings[i], myloc[aThing].idxmin()))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            f1 (tamp)  f1 (auth)\n",
      "classifier                      \n",
      "NB           0.147575   0.687539\n",
      "dt           0.169907   0.863322\n",
      "rf           0.201927   0.899418\n",
      "svm          0.190382   0.886669\n",
      "\n",
      "\n",
      "The best method of classifying for the minority class is rf\n",
      "The worst method of classifying for the minority class is NB\n",
      "The best method of classifying for the majority class is rf\n",
      "The worst method of classifying for the majority class is NB\n",
      "The best method of classifying for the both classes is rf\n",
      "The worst method of classifying for the both classes is NB\n",
      "The best method of classifying for the accuracy is rf\n",
      "The worst method of classifying for the accuracy is NB\n"
     ]
    }
   ],
   "source": [
    "df3 = df.groupby(['classifier']).mean()\n",
    "myloc = df3\n",
    "print(myloc[['f1 (tamp)', 'f1 (auth)']])\n",
    "print('\\n')\n",
    "assessThese = ['f1 (tamp)', 'f1 (auth)', 'total f1', 'accuracy']\n",
    "assessTheseMeanings = ['minority class', 'majority class', 'both classes', 'accuracy']\n",
    "for i, aThing in enumerate(assessThese):\n",
    "    print(\"The best method of classifying for the {} is {}\".format(assessTheseMeanings[i], myloc[aThing].idxmax()))\n",
    "    print(\"The worst method of classifying for the {} is {}\".format(assessTheseMeanings[i], myloc[aThing].idxmin()))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           f1 (tamp)  f1 (auth)\n",
      "data                           \n",
      "d_i_k_q_    0.193680   0.791107\n",
      "d_i_k_q_b   0.185967   0.853614\n",
      "d_q_        0.169974   0.771359\n",
      "d_q_b       0.173956   0.838425\n",
      "q_          0.185780   0.860773\n",
      "q_b         0.155328   0.890144\n",
      "\n",
      "\n",
      "The best features for the minority class is d_i_k_q_\n",
      "The worst features for the minority class is q_b\n",
      "The best features for the majority class is q_b\n",
      "The worst features for the majority class is d_q_\n",
      "The best features for the both classes is d_i_k_q_b\n",
      "The worst features for the both classes is d_q_\n",
      "The best features for the accuracy is q_b\n",
      "The worst features for the accuracy is d_q_\n"
     ]
    }
   ],
   "source": [
    "df4 = df.groupby(['data']).mean()\n",
    "myloc = df4\n",
    "print(myloc[['f1 (tamp)', 'f1 (auth)']])\n",
    "print('\\n')\n",
    "assessThese = ['f1 (tamp)', 'f1 (auth)', 'total f1', 'accuracy']\n",
    "assessTheseMeanings = ['minority class', 'majority class', 'both classes', 'accuracy']\n",
    "for i, aThing in enumerate(assessThese):\n",
    "    print(\"The best features for the {} is {}\".format(assessTheseMeanings[i], myloc[aThing].idxmax()))\n",
    "    print(\"The worst features for the {} is {}\".format(assessTheseMeanings[i], myloc[aThing].idxmin()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For file 01_TANK_f:\n",
      "           f1 (tamp)  f1 (auth)   f1 mine\n",
      "balancing                                \n",
      "-           0.040736   0.903638  0.985110\n",
      "ru          0.186892   0.803028  1.176813\n",
      "ro          0.189278   0.822257  1.200812\n",
      "s           0.191957   0.827127  1.211041\n",
      "\n",
      "\n",
      "The best method of balancing for the minority class is s\n",
      "The worst method of balancing for the minority class is -\n",
      "The best method of balancing for the majority class is -\n",
      "The worst method of balancing for the majority class is ru\n",
      "The best method of balancing for the both classes is s\n",
      "The worst method of balancing for the both classes is -\n",
      "The best method of balancing for the mine is s\n",
      "The worst method of balancing for the mine is -\n",
      "The best method of balancing for the accuracy is -\n",
      "The worst method of balancing for the accuracy is ru\n",
      "            f1 (tamp)  f1 (auth)   f1 mine\n",
      "classifier                                \n",
      "NB           0.107621   0.667168  0.882409\n",
      "dt           0.152866   0.868704  1.174436\n",
      "svm          0.173958   0.903492  1.251407\n",
      "rf           0.174419   0.916686  1.265524\n",
      "\n",
      "\n",
      "The best method of classifying for the minority class is rf\n",
      "The worst method of classifying for the minority class is NB\n",
      "The best method of classifying for the majority class is rf\n",
      "The worst method of classifying for the majority class is NB\n",
      "The best method of classifying for the both classes is rf\n",
      "The worst method of classifying for the both classes is NB\n",
      "The best method of classifying for the mine is rf\n",
      "The worst method of classifying for the mine is NB\n",
      "The best method of classifying for the accuracy is rf\n",
      "The worst method of classifying for the accuracy is NB\n",
      "           f1 (tamp)  f1 (auth)   f1 mine\n",
      "data                                     \n",
      "q_b         0.101589   0.871308  1.074487\n",
      "d_i_k_q_    0.172857   0.730204  1.075918\n",
      "d_q_        0.181236   0.735307  1.097779\n",
      "d_q_b       0.117352   0.877412  1.112115\n",
      "d_i_k_q_b   0.116811   0.892320  1.125942\n",
      "q_          0.223449   0.927524  1.374423\n",
      "\n",
      "\n",
      "The best features for the minority class is q_\n",
      "The worst features for the minority class is q_b\n",
      "The best features for the majority class is q_\n",
      "The worst features for the majority class is d_i_k_q_\n",
      "The best features for the both classes is q_\n",
      "The worst features for the both classes is d_i_k_q_\n",
      "The best features for the mine is q_\n",
      "The worst features for the mine is q_b\n",
      "The best features for the accuracy is q_\n",
      "The worst features for the accuracy is d_i_k_q_\n",
      "\n",
      "\n",
      "['01_TANK_f', 's', 'rf', 'q_', '-', 'NB', 'q_b']\n",
      "For file 02_MAN_f:\n",
      "           f1 (tamp)  f1 (auth)   f1 mine\n",
      "balancing                                \n",
      "-           0.241569   0.945637  1.428776\n",
      "s           0.299066   0.848286  1.446417\n",
      "ro          0.307782   0.845519  1.461082\n",
      "ru          0.318450   0.839061  1.475961\n",
      "\n",
      "\n",
      "The best method of balancing for the minority class is ru\n",
      "The worst method of balancing for the minority class is -\n",
      "The best method of balancing for the majority class is -\n",
      "The worst method of balancing for the majority class is ru\n",
      "The best method of balancing for the both classes is -\n",
      "The worst method of balancing for the both classes is s\n",
      "The best method of balancing for the mine is ru\n",
      "The worst method of balancing for the mine is -\n",
      "The best method of balancing for the accuracy is -\n",
      "The worst method of balancing for the accuracy is ru\n",
      "            f1 (tamp)  f1 (auth)   f1 mine\n",
      "classifier                                \n",
      "dt           0.278807   0.839775  1.397388\n",
      "rf           0.285059   0.877572  1.447691\n",
      "svm          0.296035   0.868008  1.460079\n",
      "NB           0.306965   0.893148  1.507079\n",
      "\n",
      "\n",
      "The best method of classifying for the minority class is NB\n",
      "The worst method of classifying for the minority class is dt\n",
      "The best method of classifying for the majority class is NB\n",
      "The worst method of classifying for the majority class is dt\n",
      "The best method of classifying for the both classes is NB\n",
      "The worst method of classifying for the both classes is dt\n",
      "The best method of classifying for the mine is NB\n",
      "The worst method of classifying for the mine is dt\n",
      "The best method of classifying for the accuracy is NB\n",
      "The worst method of classifying for the accuracy is dt\n",
      "           f1 (tamp)  f1 (auth)   f1 mine\n",
      "data                                     \n",
      "q_b         0.147424   0.816256  1.111104\n",
      "d_i_k_q_b   0.185128   0.874038  1.244294\n",
      "d_q_b       0.204110   0.864001  1.272221\n",
      "d_q_        0.392532   0.881737  1.666801\n",
      "q_          0.393310   0.882159  1.668779\n",
      "d_i_k_q_    0.427797   0.899563  1.755157\n",
      "\n",
      "\n",
      "The best features for the minority class is d_i_k_q_\n",
      "The worst features for the minority class is q_b\n",
      "The best features for the majority class is d_i_k_q_\n",
      "The worst features for the majority class is q_b\n",
      "The best features for the both classes is d_i_k_q_\n",
      "The worst features for the both classes is q_b\n",
      "The best features for the mine is d_i_k_q_\n",
      "The worst features for the mine is q_b\n",
      "The best features for the accuracy is d_i_k_q_\n",
      "The worst features for the accuracy is q_b\n",
      "\n",
      "\n",
      "['02_MAN_f', 'ru', 'NB', 'd_i_k_q_', '-', 'NB', 'q_b']\n",
      "For file 03_CAT_f:\n",
      "           f1 (tamp)  f1 (auth)   f1 mine\n",
      "balancing                                \n",
      "ru          0.021517   0.718889  0.761923\n",
      "s           0.029636   0.755986  0.815257\n",
      "ro          0.040890   0.756126  0.837906\n",
      "-           0.003229   0.912368  0.918826\n",
      "\n",
      "\n",
      "The best method of balancing for the minority class is ro\n",
      "The worst method of balancing for the minority class is -\n",
      "The best method of balancing for the majority class is -\n",
      "The worst method of balancing for the majority class is ru\n",
      "The best method of balancing for the both classes is -\n",
      "The worst method of balancing for the both classes is ru\n",
      "The best method of balancing for the mine is -\n",
      "The worst method of balancing for the mine is ru\n",
      "The best method of balancing for the accuracy is -\n",
      "The worst method of balancing for the accuracy is ru\n",
      "            f1 (tamp)  f1 (auth)   f1 mine\n",
      "classifier                                \n",
      "NB           0.016013   0.588464  0.620491\n",
      "dt           0.016315   0.827128  0.859759\n",
      "svm          0.026171   0.856149  0.908490\n",
      "rf           0.036772   0.871628  0.945172\n",
      "\n",
      "\n",
      "The best method of classifying for the minority class is rf\n",
      "The worst method of classifying for the minority class is NB\n",
      "The best method of classifying for the majority class is rf\n",
      "The worst method of classifying for the majority class is NB\n",
      "The best method of classifying for the both classes is rf\n",
      "The worst method of classifying for the both classes is NB\n",
      "The best method of classifying for the mine is rf\n",
      "The worst method of classifying for the mine is NB\n",
      "The best method of classifying for the accuracy is rf\n",
      "The worst method of classifying for the accuracy is NB\n",
      "           f1 (tamp)  f1 (auth)   f1 mine\n",
      "data                                     \n",
      "d_q_        0.012079   0.662144  0.686301\n",
      "d_i_k_q_    0.012435   0.683431  0.708301\n",
      "q_          0.010142   0.758034  0.778318\n",
      "d_q_b       0.036846   0.854538  0.928230\n",
      "q_b         0.027759   0.887687  0.943206\n",
      "d_i_k_q_b   0.043647   0.869220  0.956513\n",
      "\n",
      "\n",
      "The best features for the minority class is d_i_k_q_b\n",
      "The worst features for the minority class is q_\n",
      "The best features for the majority class is q_b\n",
      "The worst features for the majority class is d_q_\n",
      "The best features for the both classes is d_i_k_q_b\n",
      "The worst features for the both classes is d_q_\n",
      "The best features for the mine is d_i_k_q_b\n",
      "The worst features for the mine is d_q_\n",
      "The best features for the accuracy is q_b\n",
      "The worst features for the accuracy is d_q_\n",
      "\n",
      "\n",
      "['03_CAT_f', '-', 'rf', 'd_i_k_q_b', 's', 'NB', 'q_b']\n",
      "For file 04_HELICOPTER_f:\n",
      "           f1 (tamp)  f1 (auth)   f1 mine\n",
      "balancing                                \n",
      "-           0.079713   0.852380  1.011806\n",
      "ru          0.196407   0.723944  1.116758\n",
      "s           0.210685   0.729891  1.151260\n",
      "ro          0.209926   0.738398  1.158249\n",
      "\n",
      "\n",
      "The best method of balancing for the minority class is s\n",
      "The worst method of balancing for the minority class is -\n",
      "The best method of balancing for the majority class is -\n",
      "The worst method of balancing for the majority class is ru\n",
      "The best method of balancing for the both classes is ro\n",
      "The worst method of balancing for the both classes is ru\n",
      "The best method of balancing for the mine is ro\n",
      "The worst method of balancing for the mine is -\n",
      "The best method of balancing for the accuracy is -\n",
      "The worst method of balancing for the accuracy is ru\n",
      "            f1 (tamp)  f1 (auth)   f1 mine\n",
      "classifier                                \n",
      "NB           0.138514   0.466964  0.743992\n",
      "dt           0.135769   0.814140  1.085678\n",
      "svm          0.186323   0.874641  1.247287\n",
      "rf           0.236124   0.888868  1.361117\n",
      "\n",
      "\n",
      "The best method of classifying for the minority class is rf\n",
      "The worst method of classifying for the minority class is dt\n",
      "The best method of classifying for the majority class is rf\n",
      "The worst method of classifying for the majority class is NB\n",
      "The best method of classifying for the both classes is rf\n",
      "The worst method of classifying for the both classes is NB\n",
      "The best method of classifying for the mine is rf\n",
      "The worst method of classifying for the mine is NB\n",
      "The best method of classifying for the accuracy is rf\n",
      "The worst method of classifying for the accuracy is NB\n",
      "           f1 (tamp)  f1 (auth)   f1 mine\n",
      "data                                     \n",
      "d_q_        0.137259   0.675489  0.950007\n",
      "d_i_k_q_    0.157023   0.680102  0.994149\n",
      "d_q_b       0.182755   0.721288  1.086798\n",
      "d_i_k_q_b   0.216360   0.729329  1.162049\n",
      "q_          0.159064   0.889980  1.208108\n",
      "q_b         0.192635   0.870730  1.256000\n",
      "\n",
      "\n",
      "The best features for the minority class is d_i_k_q_b\n",
      "The worst features for the minority class is d_q_\n",
      "The best features for the majority class is q_\n",
      "The worst features for the majority class is d_q_\n",
      "The best features for the both classes is q_b\n",
      "The worst features for the both classes is d_q_\n",
      "The best features for the mine is q_b\n",
      "The worst features for the mine is d_q_\n",
      "The best features for the accuracy is q_\n",
      "The worst features for the accuracy is d_q_\n",
      "\n",
      "\n",
      "['04_HELICOPTER_f', 'ro', 'rf', 'q_b', 's', 'NB', 'q_b']\n",
      "For file 05_HEN_f:\n",
      "           f1 (tamp)  f1 (auth)   f1 mine\n",
      "balancing                                \n",
      "ru          0.144746   0.784156  1.073647\n",
      "-           0.090933   0.925318  1.107183\n",
      "ro          0.155615   0.799531  1.110761\n",
      "s           0.157448   0.803158  1.118055\n",
      "\n",
      "\n",
      "The best method of balancing for the minority class is s\n",
      "The worst method of balancing for the minority class is -\n",
      "The best method of balancing for the majority class is -\n",
      "The worst method of balancing for the majority class is ru\n",
      "The best method of balancing for the both classes is -\n",
      "The worst method of balancing for the both classes is ru\n",
      "The best method of balancing for the mine is s\n",
      "The worst method of balancing for the mine is ru\n",
      "The best method of balancing for the accuracy is -\n",
      "The worst method of balancing for the accuracy is ru\n",
      "            f1 (tamp)  f1 (auth)   f1 mine\n",
      "classifier                                \n",
      "NB           0.088349   0.680608  0.857306\n",
      "dt           0.139102   0.871794  1.149997\n",
      "svm          0.152452   0.872527  1.177431\n",
      "rf           0.168839   0.887235  1.224913\n",
      "\n",
      "\n",
      "The best method of classifying for the minority class is rf\n",
      "The worst method of classifying for the minority class is NB\n",
      "The best method of classifying for the majority class is rf\n",
      "The worst method of classifying for the majority class is NB\n",
      "The best method of classifying for the both classes is rf\n",
      "The worst method of classifying for the both classes is NB\n",
      "The best method of classifying for the mine is rf\n",
      "The worst method of classifying for the mine is NB\n",
      "The best method of classifying for the accuracy is rf\n",
      "The worst method of classifying for the accuracy is NB\n",
      "           f1 (tamp)  f1 (auth)   f1 mine\n",
      "data                                     \n",
      "q_          0.100432   0.811979  1.012843\n",
      "d_i_k_q_    0.109774   0.811334  1.030882\n",
      "d_q_b       0.161276   0.776248  1.098800\n",
      "d_q_        0.118011   0.893508  1.129530\n",
      "d_i_k_q_b   0.189426   0.779788  1.158640\n",
      "q_b         0.144193   0.895388  1.183775\n",
      "\n",
      "\n",
      "The best features for the minority class is d_i_k_q_b\n",
      "The worst features for the minority class is q_\n",
      "The best features for the majority class is q_b\n",
      "The worst features for the majority class is d_q_b\n",
      "The best features for the both classes is q_b\n",
      "The worst features for the both classes is d_q_b\n",
      "The best features for the mine is q_b\n",
      "The worst features for the mine is q_\n",
      "The best features for the accuracy is q_b\n",
      "The worst features for the accuracy is d_q_b\n",
      "\n",
      "\n",
      "['05_HEN_f', 's', 'rf', 'q_b', 'ru', 'NB', 'q_b']\n",
      "For file 06_LION_f:\n",
      "           f1 (tamp)  f1 (auth)   f1 mine\n",
      "balancing                                \n",
      "ru          0.370580   0.840398  1.581558\n",
      "ro          0.384239   0.839616  1.608095\n",
      "s           0.390305   0.845844  1.626454\n",
      "-           0.506033   0.922728  1.934793\n",
      "\n",
      "\n",
      "The best method of balancing for the minority class is -\n",
      "The worst method of balancing for the minority class is ru\n",
      "The best method of balancing for the majority class is -\n",
      "The worst method of balancing for the majority class is ro\n",
      "The best method of balancing for the both classes is -\n",
      "The worst method of balancing for the both classes is ru\n",
      "The best method of balancing for the mine is -\n",
      "The worst method of balancing for the mine is ru\n",
      "The best method of balancing for the accuracy is -\n",
      "The worst method of balancing for the accuracy is ru\n",
      "            f1 (tamp)  f1 (auth)   f1 mine\n",
      "classifier                                \n",
      "NB           0.349204   0.734268  1.432676\n",
      "dt           0.380907   0.889315  1.651128\n",
      "svm          0.445844   0.910158  1.801846\n",
      "rf           0.475202   0.914846  1.865249\n",
      "\n",
      "\n",
      "The best method of classifying for the minority class is rf\n",
      "The worst method of classifying for the minority class is NB\n",
      "The best method of classifying for the majority class is rf\n",
      "The worst method of classifying for the majority class is NB\n",
      "The best method of classifying for the both classes is rf\n",
      "The worst method of classifying for the both classes is NB\n",
      "The best method of classifying for the mine is rf\n",
      "The worst method of classifying for the mine is NB\n",
      "The best method of classifying for the accuracy is rf\n",
      "The worst method of classifying for the accuracy is NB\n",
      "           f1 (tamp)  f1 (auth)   f1 mine\n",
      "data                                     \n",
      "d_q_        0.307394   0.724056  1.338843\n",
      "d_i_k_q_    0.394286   0.784713  1.573285\n",
      "q_          0.394318   0.883861  1.672496\n",
      "q_b         0.425883   0.927713  1.779480\n",
      "d_q_b       0.464064   0.927900  1.856028\n",
      "d_i_k_q_b   0.490790   0.924638  1.906217\n",
      "\n",
      "\n",
      "The best features for the minority class is d_i_k_q_b\n",
      "The worst features for the minority class is d_q_\n",
      "The best features for the majority class is d_q_b\n",
      "The worst features for the majority class is d_q_\n",
      "The best features for the both classes is d_i_k_q_b\n",
      "The worst features for the both classes is d_q_\n",
      "The best features for the mine is d_i_k_q_b\n",
      "The worst features for the mine is d_q_\n",
      "The best features for the accuracy is d_q_b\n",
      "The worst features for the accuracy is d_q_\n",
      "\n",
      "\n",
      "['06_LION_f', '-', 'rf', 'd_i_k_q_b', 's', 'NB', 'q_b']\n",
      "For file 07_UFO_f:\n",
      "           f1 (tamp)  f1 (auth)   f1 mine\n",
      "balancing                                \n",
      "ru          0.005835   0.739426  0.751095\n",
      "ro          0.008432   0.772545  0.789408\n",
      "s           0.008738   0.794331  0.811808\n",
      "-           0.000742   0.920709  0.922193\n",
      "\n",
      "\n",
      "The best method of balancing for the minority class is s\n",
      "The worst method of balancing for the minority class is -\n",
      "The best method of balancing for the majority class is -\n",
      "The worst method of balancing for the majority class is ru\n",
      "The best method of balancing for the both classes is -\n",
      "The worst method of balancing for the both classes is ru\n",
      "The best method of balancing for the mine is -\n",
      "The worst method of balancing for the mine is ru\n",
      "The best method of balancing for the accuracy is -\n",
      "The worst method of balancing for the accuracy is ru\n",
      "            f1 (tamp)  f1 (auth)   f1 mine\n",
      "classifier                                \n",
      "NB           0.004382   0.642358  0.651122\n",
      "dt           0.005437   0.843709  0.854583\n",
      "svm          0.008336   0.861693  0.878364\n",
      "rf           0.005592   0.879252  0.890435\n",
      "\n",
      "\n",
      "The best method of classifying for the minority class is svm\n",
      "The worst method of classifying for the minority class is NB\n",
      "The best method of classifying for the majority class is rf\n",
      "The worst method of classifying for the majority class is NB\n",
      "The best method of classifying for the both classes is rf\n",
      "The worst method of classifying for the both classes is NB\n",
      "The best method of classifying for the mine is rf\n",
      "The worst method of classifying for the mine is NB\n",
      "The best method of classifying for the accuracy is rf\n",
      "The worst method of classifying for the accuracy is NB\n",
      "           f1 (tamp)  f1 (auth)   f1 mine\n",
      "data                                     \n",
      "d_q_        0.003163   0.623611  0.629936\n",
      "d_i_k_q_    0.004279   0.764022  0.772581\n",
      "q_          0.002975   0.776556  0.782507\n",
      "d_q_b       0.008512   0.852470  0.869493\n",
      "d_i_k_q_b   0.009151   0.895632  0.913934\n",
      "q_b         0.007539   0.928226  0.943304\n",
      "\n",
      "\n",
      "The best features for the minority class is d_i_k_q_b\n",
      "The worst features for the minority class is q_\n",
      "The best features for the majority class is q_b\n",
      "The worst features for the majority class is d_q_\n",
      "The best features for the both classes is d_i_k_q_b\n",
      "The worst features for the both classes is d_q_\n",
      "The best features for the mine is q_b\n",
      "The worst features for the mine is d_q_\n",
      "The best features for the accuracy is q_b\n",
      "The worst features for the accuracy is d_q_\n",
      "\n",
      "\n",
      "['07_UFO_f', '-', 'rf', 'q_b', 's', 'NB', 'q_b']\n",
      "For file 08_TREE_f:\n",
      "           f1 (tamp)  f1 (auth)   f1 mine\n",
      "balancing                                \n",
      "s           0.249676   0.882129  1.381482\n",
      "ru          0.254818   0.882728  1.392364\n",
      "ro          0.255194   0.886541  1.396930\n",
      "-           0.334283   0.963645  1.632211\n",
      "\n",
      "\n",
      "The best method of balancing for the minority class is -\n",
      "The worst method of balancing for the minority class is s\n",
      "The best method of balancing for the majority class is -\n",
      "The worst method of balancing for the majority class is s\n",
      "The best method of balancing for the both classes is -\n",
      "The worst method of balancing for the both classes is s\n",
      "The best method of balancing for the mine is -\n",
      "The worst method of balancing for the mine is s\n",
      "The best method of balancing for the accuracy is -\n",
      "The worst method of balancing for the accuracy is ru\n",
      "            f1 (tamp)  f1 (auth)   f1 mine\n",
      "classifier                                \n",
      "NB           0.196246   0.844823  1.237314\n",
      "dt           0.286591   0.913852  1.487035\n",
      "svm          0.302688   0.926075  1.531450\n",
      "rf           0.308447   0.930293  1.547187\n",
      "\n",
      "\n",
      "The best method of classifying for the minority class is rf\n",
      "The worst method of classifying for the minority class is NB\n",
      "The best method of classifying for the majority class is rf\n",
      "The worst method of classifying for the majority class is NB\n",
      "The best method of classifying for the both classes is rf\n",
      "The worst method of classifying for the both classes is NB\n",
      "The best method of classifying for the mine is rf\n",
      "The worst method of classifying for the mine is NB\n",
      "The best method of classifying for the accuracy is rf\n",
      "The worst method of classifying for the accuracy is NB\n",
      "           f1 (tamp)  f1 (auth)   f1 mine\n",
      "data                                     \n",
      "q_b         0.188959   0.916503  1.294422\n",
      "d_i_k_q_b   0.256898   0.889443  1.403238\n",
      "d_q_b       0.254909   0.894998  1.404816\n",
      "d_q_        0.259168   0.900360  1.418696\n",
      "q_          0.295587   0.889264  1.480438\n",
      "d_i_k_q_    0.385436   0.931998  1.702869\n",
      "\n",
      "\n",
      "The best features for the minority class is d_i_k_q_\n",
      "The worst features for the minority class is q_b\n",
      "The best features for the majority class is d_i_k_q_\n",
      "The worst features for the majority class is q_\n",
      "The best features for the both classes is d_i_k_q_\n",
      "The worst features for the both classes is q_b\n",
      "The best features for the mine is d_i_k_q_\n",
      "The worst features for the mine is q_b\n",
      "The best features for the accuracy is d_i_k_q_\n",
      "The worst features for the accuracy is q_\n",
      "\n",
      "\n",
      "['08_TREE_f', '-', 'rf', 'd_i_k_q_', 's', 'NB', 'q_b']\n",
      "For file 09_GIRL_f:\n",
      "           f1 (tamp)  f1 (auth)   f1 mine\n",
      "balancing                                \n",
      "ru          0.056666   0.748364  0.861696\n",
      "ro          0.059075   0.767196  0.885347\n",
      "s           0.057932   0.774927  0.890790\n",
      "-           0.009548   0.895743  0.914839\n",
      "\n",
      "\n",
      "The best method of balancing for the minority class is ro\n",
      "The worst method of balancing for the minority class is -\n",
      "The best method of balancing for the majority class is -\n",
      "The worst method of balancing for the majority class is ru\n",
      "The best method of balancing for the both classes is -\n",
      "The worst method of balancing for the both classes is ru\n",
      "The best method of balancing for the mine is -\n",
      "The worst method of balancing for the mine is ru\n",
      "The best method of balancing for the accuracy is -\n",
      "The worst method of balancing for the accuracy is ru\n",
      "            f1 (tamp)  f1 (auth)   f1 mine\n",
      "classifier                                \n",
      "NB           0.039957   0.545475  0.625388\n",
      "dt           0.045236   0.851750  0.942222\n",
      "svm          0.049286   0.883043  0.981616\n",
      "rf           0.048742   0.905962  1.003446\n",
      "\n",
      "\n",
      "The best method of classifying for the minority class is svm\n",
      "The worst method of classifying for the minority class is NB\n",
      "The best method of classifying for the majority class is rf\n",
      "The worst method of classifying for the majority class is NB\n",
      "The best method of classifying for the both classes is rf\n",
      "The worst method of classifying for the both classes is NB\n",
      "The best method of classifying for the mine is rf\n",
      "The worst method of classifying for the mine is NB\n",
      "The best method of classifying for the accuracy is rf\n",
      "The worst method of classifying for the accuracy is NB\n",
      "           f1 (tamp)  f1 (auth)   f1 mine\n",
      "data                                     \n",
      "d_q_        0.045358   0.688819  0.779536\n",
      "d_i_k_q_    0.056967   0.741353  0.855287\n",
      "d_q_b       0.041981   0.789733  0.873695\n",
      "d_i_k_q_b   0.043530   0.804936  0.891995\n",
      "q_          0.048997   0.861694  0.959689\n",
      "q_b         0.037998   0.892810  0.968806\n",
      "\n",
      "\n",
      "The best features for the minority class is d_i_k_q_\n",
      "The worst features for the minority class is q_b\n",
      "The best features for the majority class is q_b\n",
      "The worst features for the majority class is d_q_\n",
      "The best features for the both classes is q_b\n",
      "The worst features for the both classes is d_q_\n",
      "The best features for the mine is q_b\n",
      "The worst features for the mine is d_q_\n",
      "The best features for the accuracy is q_b\n",
      "The worst features for the accuracy is d_q_\n",
      "\n",
      "\n",
      "['09_GIRL_f', '-', 'rf', 'q_b', 's', 'NB', 'q_b']\n",
      "For file 10_DOG_f:\n",
      "           f1 (tamp)  f1 (auth)   f1 mine\n",
      "balancing                                \n",
      "-           0.170818   0.956404  1.298040\n",
      "ru          0.273565   0.857074  1.404204\n",
      "ro          0.291503   0.872043  1.455049\n",
      "s           0.293446   0.872391  1.459283\n",
      "\n",
      "\n",
      "The best method of balancing for the minority class is s\n",
      "The worst method of balancing for the minority class is -\n",
      "The best method of balancing for the majority class is -\n",
      "The worst method of balancing for the majority class is ru\n",
      "The best method of balancing for the both classes is s\n",
      "The worst method of balancing for the both classes is -\n",
      "The best method of balancing for the mine is s\n",
      "The worst method of balancing for the mine is -\n",
      "The best method of balancing for the accuracy is -\n",
      "The worst method of balancing for the accuracy is ru\n",
      "            f1 (tamp)  f1 (auth)   f1 mine\n",
      "classifier                                \n",
      "NB           0.228496   0.812111  1.269102\n",
      "dt           0.258036   0.913053  1.429125\n",
      "svm          0.262724   0.910905  1.436352\n",
      "rf           0.280077   0.921843  1.481998\n",
      "\n",
      "\n",
      "The best method of classifying for the minority class is rf\n",
      "The worst method of classifying for the minority class is NB\n",
      "The best method of classifying for the majority class is rf\n",
      "The worst method of classifying for the majority class is NB\n",
      "The best method of classifying for the both classes is rf\n",
      "The worst method of classifying for the both classes is NB\n",
      "The best method of classifying for the mine is rf\n",
      "The worst method of classifying for the mine is NB\n",
      "The best method of classifying for the accuracy is rf\n",
      "The worst method of classifying for the accuracy is NB\n",
      "           f1 (tamp)  f1 (auth)   f1 mine\n",
      "data                                     \n",
      "d_i_k_q_    0.215943   0.884350  1.316236\n",
      "d_q_b       0.267760   0.825662  1.361181\n",
      "q_          0.229525   0.926676  1.385727\n",
      "d_q_        0.243537   0.928560  1.415633\n",
      "q_b         0.279303   0.894822  1.453429\n",
      "d_i_k_q_b   0.307930   0.876799  1.492660\n",
      "\n",
      "\n",
      "The best features for the minority class is d_i_k_q_b\n",
      "The worst features for the minority class is d_i_k_q_\n",
      "The best features for the majority class is d_q_\n",
      "The worst features for the majority class is d_q_b\n",
      "The best features for the both classes is d_i_k_q_b\n",
      "The worst features for the both classes is d_q_b\n",
      "The best features for the mine is d_i_k_q_b\n",
      "The worst features for the mine is d_i_k_q_\n",
      "The best features for the accuracy is d_q_\n",
      "The worst features for the accuracy is d_q_b\n",
      "\n",
      "\n",
      "['10_DOG_f', 's', 'rf', 'd_i_k_q_b', 'ru', 'NB', 'q_b']\n"
     ]
    }
   ],
   "source": [
    "fileFeatureList = []\n",
    "headings = ['FileName', 'bestBalance(avg)', 'bestClass(avg)', 'bestFeat(avg)', \n",
    "            'bestBalance(max)', 'bestClass(max)', 'bestFeat(max)',]\n",
    "fileFeatureList.append(headings)\n",
    "bestBy = 'f1 mine'\n",
    "resultDf = pd.DataFrame()\n",
    "maxesOnly = pd.DataFrame()\n",
    "minsOnly = pd.DataFrame()\n",
    "\n",
    "for file in df['File'].unique():\n",
    "#for file in ['01_TANK_f']:\n",
    "    fileResults = []\n",
    "    fileResults.append(file)\n",
    "    mydf = df.loc[df['File'] == file]\n",
    "    # Let the minority class be twice as important as the majority class...?\n",
    "    assessThese = ['f1 (tamp)', 'f1 (auth)', 'total f1', 'f1 mine', 'accuracy']\n",
    "    assessTheseMeanings = ['minority class', 'majority class', 'both classes', 'mine', 'accuracy']\n",
    "    printThese = ['f1 (tamp)', 'f1 (auth)', 'f1 mine']\n",
    "    sortedBy = 'f1 mine'\n",
    "\n",
    "    \n",
    "    print(\"For file {}:\".format(file))\n",
    "    df2 = mydf.groupby(['balancing']).mean()\n",
    "    myloc = df2\n",
    "    print(myloc[printThese].sort_values(by=[sortedBy], ascending=True))\n",
    "    print('\\n')\n",
    "    fileResults.append(myloc['f1 mine'].idxmax())\n",
    "    for i, aThing in enumerate(assessThese):\n",
    "        print(\"The best method of balancing for the {} is {}\".format(assessTheseMeanings[i], myloc[aThing].idxmax()))\n",
    "        print(\"The worst method of balancing for the {} is {}\".format(assessTheseMeanings[i], myloc[aThing].idxmin()))\n",
    "\n",
    "\n",
    "    df3 = mydf.groupby(['classifier']).mean()\n",
    "    myloc = df3\n",
    "    print(myloc[printThese].sort_values(by=[sortedBy], ascending=True))\n",
    "    print('\\n')\n",
    "    fileResults.append(myloc['f1 mine'].idxmax())\n",
    "    for i, aThing in enumerate(assessThese):\n",
    "        print(\"The best method of classifying for the {} is {}\".format(assessTheseMeanings[i], myloc[aThing].idxmax()))\n",
    "        print(\"The worst method of classifying for the {} is {}\".format(assessTheseMeanings[i], myloc[aThing].idxmin()))\n",
    "\n",
    "    df4 = mydf.groupby(['data']).mean()\n",
    "    myloc = df4\n",
    "    print(myloc[printThese].sort_values(by=[sortedBy], ascending=True))\n",
    "    print('\\n')\n",
    "    fileResults.append(myloc['f1 mine'].idxmax())\n",
    "    for i, aThing in enumerate(assessThese):\n",
    "        print(\"The best features for the {} is {}\".format(assessTheseMeanings[i], myloc[aThing].idxmax()))\n",
    "        print(\"The worst features for the {} is {}\".format(assessTheseMeanings[i], myloc[aThing].idxmin()))\n",
    "        \n",
    "\n",
    "    print('\\n')\n",
    "    \n",
    "    \n",
    "    # last, find this maximum (but average over stratifications)\n",
    "    mydf = mydf\n",
    "    df2 = mydf.groupby(['balancing'])\n",
    "    bestBalance = df2['f1 mine'].idxmax().idxmax()\n",
    "    fileResults.append(bestBalance)\n",
    "    df3 = mydf.groupby(['classifier'])\n",
    "    bestClassifier = df3['f1 mine'].idxmax().idxmax()\n",
    "    fileResults.append(bestClassifier)\n",
    "    df4 = mydf.groupby(['data'])\n",
    "    bestData = df4['f1 mine'].idxmax().idxmax()\n",
    "    fileResults.append(bestData)\n",
    "    \n",
    "    fileFeatureList.append(fileResults)\n",
    "    \n",
    "    overallAvg = df.loc[(df['File']==file) & \n",
    "                     (df['balancing']==fileResults[1]) & \n",
    "                     (df['classifier']==fileResults[2]) &\n",
    "                     (df['data']==fileResults[3])\n",
    "                    ]\n",
    "    overallMax = df.loc[(df['File']==file) & \n",
    "                     (df['balancing']==fileResults[4]) & \n",
    "                     (df['classifier']==fileResults[5]) &\n",
    "                     (df['data']==fileResults[6])\n",
    "                    ]\n",
    "    mydf = df.loc[df['File'] == file]\n",
    "    overallMax2 = mydf.loc[[mydf['f1 mine'].idxmax()]]\n",
    "    overallMin = mydf.loc[[mydf['f1 mine'].idxmin()]]\n",
    "\n",
    "    \n",
    "    resultDf = pd.concat([resultDf, overallAvg, overallMax, overallMax2], axis=0, join='outer', ignore_index=False)\n",
    "    maxesOnly = pd.concat([maxesOnly, overallMax2])\n",
    "    minsOnly = pd.concat([overallMin])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    print(fileResults)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>data</th>\n",
       "      <th>classifier</th>\n",
       "      <th>balancing</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>total f1</th>\n",
       "      <th>imb ratio</th>\n",
       "      <th>f1 (auth)</th>\n",
       "      <th>f1 (tamp)</th>\n",
       "      <th>f1 mine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>01_TANK_f</td>\n",
       "      <td>q_</td>\n",
       "      <td>rf</td>\n",
       "      <td>s</td>\n",
       "      <td>7954.75</td>\n",
       "      <td>1292.25</td>\n",
       "      <td>221.50</td>\n",
       "      <td>281.50</td>\n",
       "      <td>0.844744</td>\n",
       "      <td>1.186290</td>\n",
       "      <td>0.054396</td>\n",
       "      <td>0.913119</td>\n",
       "      <td>0.271097</td>\n",
       "      <td>1.455312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>01_TANK_f</td>\n",
       "      <td>q_b</td>\n",
       "      <td>NB</td>\n",
       "      <td>-</td>\n",
       "      <td>9159.25</td>\n",
       "      <td>87.75</td>\n",
       "      <td>502.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.939513</td>\n",
       "      <td>0.971675</td>\n",
       "      <td>0.054396</td>\n",
       "      <td>0.968810</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.975570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>01_TANK_f</td>\n",
       "      <td>q_</td>\n",
       "      <td>NB</td>\n",
       "      <td>-</td>\n",
       "      <td>8890.25</td>\n",
       "      <td>356.75</td>\n",
       "      <td>338.00</td>\n",
       "      <td>165.00</td>\n",
       "      <td>0.928744</td>\n",
       "      <td>1.287490</td>\n",
       "      <td>0.054396</td>\n",
       "      <td>0.962396</td>\n",
       "      <td>0.322030</td>\n",
       "      <td>1.606455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>02_MAN_f</td>\n",
       "      <td>d_i_k_q_</td>\n",
       "      <td>NB</td>\n",
       "      <td>ru</td>\n",
       "      <td>4440.50</td>\n",
       "      <td>976.50</td>\n",
       "      <td>153.00</td>\n",
       "      <td>430.00</td>\n",
       "      <td>0.811750</td>\n",
       "      <td>1.325936</td>\n",
       "      <td>0.107624</td>\n",
       "      <td>0.887168</td>\n",
       "      <td>0.432269</td>\n",
       "      <td>1.751707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>02_MAN_f</td>\n",
       "      <td>q_b</td>\n",
       "      <td>NB</td>\n",
       "      <td>-</td>\n",
       "      <td>5032.75</td>\n",
       "      <td>384.25</td>\n",
       "      <td>503.75</td>\n",
       "      <td>79.25</td>\n",
       "      <td>0.852000</td>\n",
       "      <td>1.075444</td>\n",
       "      <td>0.107624</td>\n",
       "      <td>0.918930</td>\n",
       "      <td>0.151457</td>\n",
       "      <td>1.221844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>02_MAN_f</td>\n",
       "      <td>d_q_</td>\n",
       "      <td>NB</td>\n",
       "      <td>-</td>\n",
       "      <td>5292.25</td>\n",
       "      <td>124.75</td>\n",
       "      <td>391.75</td>\n",
       "      <td>191.25</td>\n",
       "      <td>0.913917</td>\n",
       "      <td>1.382161</td>\n",
       "      <td>0.107624</td>\n",
       "      <td>0.953473</td>\n",
       "      <td>0.425473</td>\n",
       "      <td>1.804418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>03_CAT_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>-</td>\n",
       "      <td>7444.50</td>\n",
       "      <td>16.25</td>\n",
       "      <td>39.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.992633</td>\n",
       "      <td>1.001564</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.996303</td>\n",
       "      <td>0.008969</td>\n",
       "      <td>1.014240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>03_CAT_f</td>\n",
       "      <td>q_b</td>\n",
       "      <td>NB</td>\n",
       "      <td>s</td>\n",
       "      <td>5128.50</td>\n",
       "      <td>2332.25</td>\n",
       "      <td>12.25</td>\n",
       "      <td>27.00</td>\n",
       "      <td>0.687397</td>\n",
       "      <td>0.835550</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.813951</td>\n",
       "      <td>0.022514</td>\n",
       "      <td>0.858979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>03_CAT_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>ro</td>\n",
       "      <td>7343.50</td>\n",
       "      <td>117.25</td>\n",
       "      <td>18.75</td>\n",
       "      <td>20.50</td>\n",
       "      <td>0.981865</td>\n",
       "      <td>1.429961</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.990825</td>\n",
       "      <td>0.231638</td>\n",
       "      <td>1.454102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>04_HELICOPTER_f</td>\n",
       "      <td>q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>ro</td>\n",
       "      <td>11026.50</td>\n",
       "      <td>3146.00</td>\n",
       "      <td>206.25</td>\n",
       "      <td>621.25</td>\n",
       "      <td>0.776516</td>\n",
       "      <td>1.137306</td>\n",
       "      <td>0.058388</td>\n",
       "      <td>0.868049</td>\n",
       "      <td>0.270417</td>\n",
       "      <td>1.408884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>04_HELICOPTER_f</td>\n",
       "      <td>q_b</td>\n",
       "      <td>NB</td>\n",
       "      <td>s</td>\n",
       "      <td>9515.50</td>\n",
       "      <td>4657.00</td>\n",
       "      <td>252.50</td>\n",
       "      <td>575.00</td>\n",
       "      <td>0.672701</td>\n",
       "      <td>0.983529</td>\n",
       "      <td>0.058388</td>\n",
       "      <td>0.794929</td>\n",
       "      <td>0.189785</td>\n",
       "      <td>1.174498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>04_HELICOPTER_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>-</td>\n",
       "      <td>13332.25</td>\n",
       "      <td>840.25</td>\n",
       "      <td>350.50</td>\n",
       "      <td>477.00</td>\n",
       "      <td>0.920616</td>\n",
       "      <td>1.406782</td>\n",
       "      <td>0.058388</td>\n",
       "      <td>0.957252</td>\n",
       "      <td>0.444807</td>\n",
       "      <td>1.846866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>05_HEN_f</td>\n",
       "      <td>q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>s</td>\n",
       "      <td>10670.00</td>\n",
       "      <td>884.25</td>\n",
       "      <td>304.25</td>\n",
       "      <td>141.50</td>\n",
       "      <td>0.900958</td>\n",
       "      <td>1.139417</td>\n",
       "      <td>0.038579</td>\n",
       "      <td>0.947245</td>\n",
       "      <td>0.192321</td>\n",
       "      <td>1.331886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>05_HEN_f</td>\n",
       "      <td>q_b</td>\n",
       "      <td>NB</td>\n",
       "      <td>ru</td>\n",
       "      <td>7930.75</td>\n",
       "      <td>3623.50</td>\n",
       "      <td>161.75</td>\n",
       "      <td>284.00</td>\n",
       "      <td>0.684560</td>\n",
       "      <td>0.941057</td>\n",
       "      <td>0.038579</td>\n",
       "      <td>0.807335</td>\n",
       "      <td>0.130477</td>\n",
       "      <td>1.068289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>05_HEN_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>-</td>\n",
       "      <td>11343.25</td>\n",
       "      <td>211.00</td>\n",
       "      <td>311.50</td>\n",
       "      <td>134.25</td>\n",
       "      <td>0.956459</td>\n",
       "      <td>1.256839</td>\n",
       "      <td>0.038579</td>\n",
       "      <td>0.977487</td>\n",
       "      <td>0.339444</td>\n",
       "      <td>1.656375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>06_LION_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>-</td>\n",
       "      <td>6739.25</td>\n",
       "      <td>214.75</td>\n",
       "      <td>214.00</td>\n",
       "      <td>332.00</td>\n",
       "      <td>0.942833</td>\n",
       "      <td>1.576194</td>\n",
       "      <td>0.078516</td>\n",
       "      <td>0.969171</td>\n",
       "      <td>0.607641</td>\n",
       "      <td>2.184453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>06_LION_f</td>\n",
       "      <td>q_b</td>\n",
       "      <td>NB</td>\n",
       "      <td>s</td>\n",
       "      <td>5776.75</td>\n",
       "      <td>1177.25</td>\n",
       "      <td>140.75</td>\n",
       "      <td>405.25</td>\n",
       "      <td>0.824267</td>\n",
       "      <td>1.285209</td>\n",
       "      <td>0.078516</td>\n",
       "      <td>0.897603</td>\n",
       "      <td>0.380785</td>\n",
       "      <td>1.659172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>06_LION_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>s</td>\n",
       "      <td>6707.50</td>\n",
       "      <td>246.50</td>\n",
       "      <td>167.50</td>\n",
       "      <td>378.50</td>\n",
       "      <td>0.944800</td>\n",
       "      <td>1.620232</td>\n",
       "      <td>0.078516</td>\n",
       "      <td>0.970063</td>\n",
       "      <td>0.646456</td>\n",
       "      <td>2.262975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>07_UFO_f</td>\n",
       "      <td>q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>-</td>\n",
       "      <td>9737.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.998692</td>\n",
       "      <td>0.999346</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.999346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>07_UFO_f</td>\n",
       "      <td>q_b</td>\n",
       "      <td>NB</td>\n",
       "      <td>s</td>\n",
       "      <td>7383.75</td>\n",
       "      <td>2353.50</td>\n",
       "      <td>2.75</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.758330</td>\n",
       "      <td>0.869165</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.862399</td>\n",
       "      <td>0.008417</td>\n",
       "      <td>0.879232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>07_UFO_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>svm</td>\n",
       "      <td>ro</td>\n",
       "      <td>9493.50</td>\n",
       "      <td>243.75</td>\n",
       "      <td>7.50</td>\n",
       "      <td>5.25</td>\n",
       "      <td>0.974230</td>\n",
       "      <td>1.061329</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.986940</td>\n",
       "      <td>0.040115</td>\n",
       "      <td>1.067169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>08_TREE_f</td>\n",
       "      <td>d_i_k_q_</td>\n",
       "      <td>rf</td>\n",
       "      <td>-</td>\n",
       "      <td>8550.75</td>\n",
       "      <td>73.25</td>\n",
       "      <td>194.00</td>\n",
       "      <td>182.00</td>\n",
       "      <td>0.970306</td>\n",
       "      <td>1.556034</td>\n",
       "      <td>0.043599</td>\n",
       "      <td>0.984613</td>\n",
       "      <td>0.576634</td>\n",
       "      <td>2.137880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>08_TREE_f</td>\n",
       "      <td>q_b</td>\n",
       "      <td>NB</td>\n",
       "      <td>s</td>\n",
       "      <td>7075.75</td>\n",
       "      <td>1548.25</td>\n",
       "      <td>137.25</td>\n",
       "      <td>238.75</td>\n",
       "      <td>0.812722</td>\n",
       "      <td>1.114724</td>\n",
       "      <td>0.043599</td>\n",
       "      <td>0.893572</td>\n",
       "      <td>0.220758</td>\n",
       "      <td>1.335088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>08_TREE_f</td>\n",
       "      <td>d_i_k_q_</td>\n",
       "      <td>rf</td>\n",
       "      <td>-</td>\n",
       "      <td>8550.75</td>\n",
       "      <td>73.25</td>\n",
       "      <td>194.00</td>\n",
       "      <td>182.00</td>\n",
       "      <td>0.970306</td>\n",
       "      <td>1.556034</td>\n",
       "      <td>0.043599</td>\n",
       "      <td>0.984613</td>\n",
       "      <td>0.576634</td>\n",
       "      <td>2.137880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>09_GIRL_f</td>\n",
       "      <td>q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>-</td>\n",
       "      <td>10327.25</td>\n",
       "      <td>28.25</td>\n",
       "      <td>142.75</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.983714</td>\n",
       "      <td>1.011922</td>\n",
       "      <td>0.013954</td>\n",
       "      <td>0.991789</td>\n",
       "      <td>0.020057</td>\n",
       "      <td>1.031904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>09_GIRL_f</td>\n",
       "      <td>q_b</td>\n",
       "      <td>NB</td>\n",
       "      <td>s</td>\n",
       "      <td>7525.75</td>\n",
       "      <td>2829.75</td>\n",
       "      <td>62.75</td>\n",
       "      <td>81.75</td>\n",
       "      <td>0.724519</td>\n",
       "      <td>0.889593</td>\n",
       "      <td>0.013954</td>\n",
       "      <td>0.838804</td>\n",
       "      <td>0.053501</td>\n",
       "      <td>0.945807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>09_GIRL_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>svm</td>\n",
       "      <td>s</td>\n",
       "      <td>9147.50</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>86.25</td>\n",
       "      <td>58.25</td>\n",
       "      <td>0.876730</td>\n",
       "      <td>1.043199</td>\n",
       "      <td>0.013954</td>\n",
       "      <td>0.933931</td>\n",
       "      <td>0.082580</td>\n",
       "      <td>1.099091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>10_DOG_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>s</td>\n",
       "      <td>11617.75</td>\n",
       "      <td>380.50</td>\n",
       "      <td>439.75</td>\n",
       "      <td>312.00</td>\n",
       "      <td>0.935666</td>\n",
       "      <td>1.402113</td>\n",
       "      <td>0.062655</td>\n",
       "      <td>0.965902</td>\n",
       "      <td>0.432058</td>\n",
       "      <td>1.830018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>10_DOG_f</td>\n",
       "      <td>q_b</td>\n",
       "      <td>NB</td>\n",
       "      <td>ru</td>\n",
       "      <td>9532.25</td>\n",
       "      <td>2466.00</td>\n",
       "      <td>179.75</td>\n",
       "      <td>572.00</td>\n",
       "      <td>0.792488</td>\n",
       "      <td>1.192656</td>\n",
       "      <td>0.062655</td>\n",
       "      <td>0.878134</td>\n",
       "      <td>0.301867</td>\n",
       "      <td>1.481867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>10_DOG_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>s</td>\n",
       "      <td>11617.75</td>\n",
       "      <td>380.50</td>\n",
       "      <td>439.75</td>\n",
       "      <td>312.00</td>\n",
       "      <td>0.935666</td>\n",
       "      <td>1.402113</td>\n",
       "      <td>0.062655</td>\n",
       "      <td>0.965902</td>\n",
       "      <td>0.432058</td>\n",
       "      <td>1.830018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                File       data classifier balancing        TN       FP  \\\n",
       "75         01_TANK_f         q_         rf         s   7954.75  1292.25   \n",
       "80         01_TANK_f        q_b         NB         -   9159.25    87.75   \n",
       "64         01_TANK_f         q_         NB         -   8890.25   356.75   \n",
       "98          02_MAN_f   d_i_k_q_         NB        ru   4440.50   976.50   \n",
       "176         02_MAN_f        q_b         NB         -   5032.75   384.25   \n",
       "128         02_MAN_f       d_q_         NB         -   5292.25   124.75   \n",
       "216         03_CAT_f  d_i_k_q_b         rf         -   7444.50    16.25   \n",
       "275         03_CAT_f        q_b         NB         s   5128.50  2332.25   \n",
       "217         03_CAT_f  d_i_k_q_b         rf        ro   7343.50   117.25   \n",
       "377  04_HELICOPTER_f        q_b         rf        ro  11026.50  3146.00   \n",
       "371  04_HELICOPTER_f        q_b         NB         s   9515.50  4657.00   \n",
       "312  04_HELICOPTER_f  d_i_k_q_b         rf         -  13332.25   840.25   \n",
       "475         05_HEN_f        q_b         rf         s  10670.00   884.25   \n",
       "466         05_HEN_f        q_b         NB        ru   7930.75  3623.50   \n",
       "408         05_HEN_f  d_i_k_q_b         rf         -  11343.25   211.00   \n",
       "504        06_LION_f  d_i_k_q_b         rf         -   6739.25   214.75   \n",
       "563        06_LION_f        q_b         NB         s   5776.75  1177.25   \n",
       "507        06_LION_f  d_i_k_q_b         rf         s   6707.50   246.50   \n",
       "664         07_UFO_f        q_b         rf         -   9737.25     0.00   \n",
       "659         07_UFO_f        q_b         NB         s   7383.75  2353.50   \n",
       "605         07_UFO_f  d_i_k_q_b        svm        ro   9493.50   243.75   \n",
       "680        08_TREE_f   d_i_k_q_         rf         -   8550.75    73.25   \n",
       "755        08_TREE_f        q_b         NB         s   7075.75  1548.25   \n",
       "680        08_TREE_f   d_i_k_q_         rf         -   8550.75    73.25   \n",
       "856        09_GIRL_f        q_b         rf         -  10327.25    28.25   \n",
       "851        09_GIRL_f        q_b         NB         s   7525.75  2829.75   \n",
       "799        09_GIRL_f  d_i_k_q_b        svm         s   9147.50  1208.00   \n",
       "891         10_DOG_f  d_i_k_q_b         rf         s  11617.75   380.50   \n",
       "946         10_DOG_f        q_b         NB        ru   9532.25  2466.00   \n",
       "891         10_DOG_f  d_i_k_q_b         rf         s  11617.75   380.50   \n",
       "\n",
       "         FN      TP  accuracy  total f1  imb ratio  f1 (auth)  f1 (tamp)  \\\n",
       "75   221.50  281.50  0.844744  1.186290   0.054396   0.913119   0.271097   \n",
       "80   502.00    1.00  0.939513  0.971675   0.054396   0.968810   0.003380   \n",
       "64   338.00  165.00  0.928744  1.287490   0.054396   0.962396   0.322030   \n",
       "98   153.00  430.00  0.811750  1.325936   0.107624   0.887168   0.432269   \n",
       "176  503.75   79.25  0.852000  1.075444   0.107624   0.918930   0.151457   \n",
       "128  391.75  191.25  0.913917  1.382161   0.107624   0.953473   0.425473   \n",
       "216   39.00    0.25  0.992633  1.001564   0.005261   0.996303   0.008969   \n",
       "275   12.25   27.00  0.687397  0.835550   0.005261   0.813951   0.022514   \n",
       "217   18.75   20.50  0.981865  1.429961   0.005261   0.990825   0.231638   \n",
       "377  206.25  621.25  0.776516  1.137306   0.058388   0.868049   0.270417   \n",
       "371  252.50  575.00  0.672701  0.983529   0.058388   0.794929   0.189785   \n",
       "312  350.50  477.00  0.920616  1.406782   0.058388   0.957252   0.444807   \n",
       "475  304.25  141.50  0.900958  1.139417   0.038579   0.947245   0.192321   \n",
       "466  161.75  284.00  0.684560  0.941057   0.038579   0.807335   0.130477   \n",
       "408  311.50  134.25  0.956459  1.256839   0.038579   0.977487   0.339444   \n",
       "504  214.00  332.00  0.942833  1.576194   0.078516   0.969171   0.607641   \n",
       "563  140.75  405.25  0.824267  1.285209   0.078516   0.897603   0.380785   \n",
       "507  167.50  378.50  0.944800  1.620232   0.078516   0.970063   0.646456   \n",
       "664   12.75    0.00  0.998692  0.999346   0.001309   0.999346   0.000000   \n",
       "659    2.75   10.00  0.758330  0.869165   0.001309   0.862399   0.008417   \n",
       "605    7.50    5.25  0.974230  1.061329   0.001309   0.986940   0.040115   \n",
       "680  194.00  182.00  0.970306  1.556034   0.043599   0.984613   0.576634   \n",
       "755  137.25  238.75  0.812722  1.114724   0.043599   0.893572   0.220758   \n",
       "680  194.00  182.00  0.970306  1.556034   0.043599   0.984613   0.576634   \n",
       "856  142.75    1.75  0.983714  1.011922   0.013954   0.991789   0.020057   \n",
       "851   62.75   81.75  0.724519  0.889593   0.013954   0.838804   0.053501   \n",
       "799   86.25   58.25  0.876730  1.043199   0.013954   0.933931   0.082580   \n",
       "891  439.75  312.00  0.935666  1.402113   0.062655   0.965902   0.432058   \n",
       "946  179.75  572.00  0.792488  1.192656   0.062655   0.878134   0.301867   \n",
       "891  439.75  312.00  0.935666  1.402113   0.062655   0.965902   0.432058   \n",
       "\n",
       "      f1 mine  \n",
       "75   1.455312  \n",
       "80   0.975570  \n",
       "64   1.606455  \n",
       "98   1.751707  \n",
       "176  1.221844  \n",
       "128  1.804418  \n",
       "216  1.014240  \n",
       "275  0.858979  \n",
       "217  1.454102  \n",
       "377  1.408884  \n",
       "371  1.174498  \n",
       "312  1.846866  \n",
       "475  1.331886  \n",
       "466  1.068289  \n",
       "408  1.656375  \n",
       "504  2.184453  \n",
       "563  1.659172  \n",
       "507  2.262975  \n",
       "664  0.999346  \n",
       "659  0.879232  \n",
       "605  1.067169  \n",
       "680  2.137880  \n",
       "755  1.335088  \n",
       "680  2.137880  \n",
       "856  1.031904  \n",
       "851  0.945807  \n",
       "799  1.099091  \n",
       "891  1.830018  \n",
       "946  1.481867  \n",
       "891  1.830018  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>data</th>\n",
       "      <th>classifier</th>\n",
       "      <th>balancing</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>total f1</th>\n",
       "      <th>imb ratio</th>\n",
       "      <th>f1 (auth)</th>\n",
       "      <th>f1 (tamp)</th>\n",
       "      <th>f1 mine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>01_TANK_f</td>\n",
       "      <td>q_</td>\n",
       "      <td>NB</td>\n",
       "      <td>-</td>\n",
       "      <td>8890.25</td>\n",
       "      <td>356.75</td>\n",
       "      <td>338.00</td>\n",
       "      <td>165.00</td>\n",
       "      <td>0.928744</td>\n",
       "      <td>1.287490</td>\n",
       "      <td>0.054396</td>\n",
       "      <td>0.962396</td>\n",
       "      <td>0.322030</td>\n",
       "      <td>1.606455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>02_MAN_f</td>\n",
       "      <td>d_q_</td>\n",
       "      <td>NB</td>\n",
       "      <td>-</td>\n",
       "      <td>5292.25</td>\n",
       "      <td>124.75</td>\n",
       "      <td>391.75</td>\n",
       "      <td>191.25</td>\n",
       "      <td>0.913917</td>\n",
       "      <td>1.382161</td>\n",
       "      <td>0.107624</td>\n",
       "      <td>0.953473</td>\n",
       "      <td>0.425473</td>\n",
       "      <td>1.804418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>03_CAT_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>ro</td>\n",
       "      <td>7343.50</td>\n",
       "      <td>117.25</td>\n",
       "      <td>18.75</td>\n",
       "      <td>20.50</td>\n",
       "      <td>0.981865</td>\n",
       "      <td>1.429961</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.990825</td>\n",
       "      <td>0.231638</td>\n",
       "      <td>1.454102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>04_HELICOPTER_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>-</td>\n",
       "      <td>13332.25</td>\n",
       "      <td>840.25</td>\n",
       "      <td>350.50</td>\n",
       "      <td>477.00</td>\n",
       "      <td>0.920616</td>\n",
       "      <td>1.406782</td>\n",
       "      <td>0.058388</td>\n",
       "      <td>0.957252</td>\n",
       "      <td>0.444807</td>\n",
       "      <td>1.846866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>05_HEN_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>-</td>\n",
       "      <td>11343.25</td>\n",
       "      <td>211.00</td>\n",
       "      <td>311.50</td>\n",
       "      <td>134.25</td>\n",
       "      <td>0.956459</td>\n",
       "      <td>1.256839</td>\n",
       "      <td>0.038579</td>\n",
       "      <td>0.977487</td>\n",
       "      <td>0.339444</td>\n",
       "      <td>1.656375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>06_LION_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>s</td>\n",
       "      <td>6707.50</td>\n",
       "      <td>246.50</td>\n",
       "      <td>167.50</td>\n",
       "      <td>378.50</td>\n",
       "      <td>0.944800</td>\n",
       "      <td>1.620232</td>\n",
       "      <td>0.078516</td>\n",
       "      <td>0.970063</td>\n",
       "      <td>0.646456</td>\n",
       "      <td>2.262975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>07_UFO_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>svm</td>\n",
       "      <td>ro</td>\n",
       "      <td>9493.50</td>\n",
       "      <td>243.75</td>\n",
       "      <td>7.50</td>\n",
       "      <td>5.25</td>\n",
       "      <td>0.974230</td>\n",
       "      <td>1.061329</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.986940</td>\n",
       "      <td>0.040115</td>\n",
       "      <td>1.067169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>08_TREE_f</td>\n",
       "      <td>d_i_k_q_</td>\n",
       "      <td>rf</td>\n",
       "      <td>-</td>\n",
       "      <td>8550.75</td>\n",
       "      <td>73.25</td>\n",
       "      <td>194.00</td>\n",
       "      <td>182.00</td>\n",
       "      <td>0.970306</td>\n",
       "      <td>1.556034</td>\n",
       "      <td>0.043599</td>\n",
       "      <td>0.984613</td>\n",
       "      <td>0.576634</td>\n",
       "      <td>2.137880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>09_GIRL_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>svm</td>\n",
       "      <td>s</td>\n",
       "      <td>9147.50</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>86.25</td>\n",
       "      <td>58.25</td>\n",
       "      <td>0.876730</td>\n",
       "      <td>1.043199</td>\n",
       "      <td>0.013954</td>\n",
       "      <td>0.933931</td>\n",
       "      <td>0.082580</td>\n",
       "      <td>1.099091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>10_DOG_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>s</td>\n",
       "      <td>11617.75</td>\n",
       "      <td>380.50</td>\n",
       "      <td>439.75</td>\n",
       "      <td>312.00</td>\n",
       "      <td>0.935666</td>\n",
       "      <td>1.402113</td>\n",
       "      <td>0.062655</td>\n",
       "      <td>0.965902</td>\n",
       "      <td>0.432058</td>\n",
       "      <td>1.830018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                File       data classifier balancing        TN       FP  \\\n",
       "64         01_TANK_f         q_         NB         -   8890.25   356.75   \n",
       "128         02_MAN_f       d_q_         NB         -   5292.25   124.75   \n",
       "217         03_CAT_f  d_i_k_q_b         rf        ro   7343.50   117.25   \n",
       "312  04_HELICOPTER_f  d_i_k_q_b         rf         -  13332.25   840.25   \n",
       "408         05_HEN_f  d_i_k_q_b         rf         -  11343.25   211.00   \n",
       "507        06_LION_f  d_i_k_q_b         rf         s   6707.50   246.50   \n",
       "605         07_UFO_f  d_i_k_q_b        svm        ro   9493.50   243.75   \n",
       "680        08_TREE_f   d_i_k_q_         rf         -   8550.75    73.25   \n",
       "799        09_GIRL_f  d_i_k_q_b        svm         s   9147.50  1208.00   \n",
       "891         10_DOG_f  d_i_k_q_b         rf         s  11617.75   380.50   \n",
       "\n",
       "         FN      TP  accuracy  total f1  imb ratio  f1 (auth)  f1 (tamp)  \\\n",
       "64   338.00  165.00  0.928744  1.287490   0.054396   0.962396   0.322030   \n",
       "128  391.75  191.25  0.913917  1.382161   0.107624   0.953473   0.425473   \n",
       "217   18.75   20.50  0.981865  1.429961   0.005261   0.990825   0.231638   \n",
       "312  350.50  477.00  0.920616  1.406782   0.058388   0.957252   0.444807   \n",
       "408  311.50  134.25  0.956459  1.256839   0.038579   0.977487   0.339444   \n",
       "507  167.50  378.50  0.944800  1.620232   0.078516   0.970063   0.646456   \n",
       "605    7.50    5.25  0.974230  1.061329   0.001309   0.986940   0.040115   \n",
       "680  194.00  182.00  0.970306  1.556034   0.043599   0.984613   0.576634   \n",
       "799   86.25   58.25  0.876730  1.043199   0.013954   0.933931   0.082580   \n",
       "891  439.75  312.00  0.935666  1.402113   0.062655   0.965902   0.432058   \n",
       "\n",
       "      f1 mine  \n",
       "64   1.606455  \n",
       "128  1.804418  \n",
       "217  1.454102  \n",
       "312  1.846866  \n",
       "408  1.656375  \n",
       "507  2.262975  \n",
       "605  1.067169  \n",
       "680  2.137880  \n",
       "799  1.099091  \n",
       "891  1.830018  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxesOnly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>data</th>\n",
       "      <th>classifier</th>\n",
       "      <th>balancing</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>total f1</th>\n",
       "      <th>imb ratio</th>\n",
       "      <th>f1 (auth)</th>\n",
       "      <th>f1 (tamp)</th>\n",
       "      <th>f1 mine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>01_TANK_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>ro</td>\n",
       "      <td>8976.75</td>\n",
       "      <td>270.25</td>\n",
       "      <td>432.25</td>\n",
       "      <td>70.75</td>\n",
       "      <td>0.927949</td>\n",
       "      <td>1.123273</td>\n",
       "      <td>0.054396</td>\n",
       "      <td>0.962345</td>\n",
       "      <td>0.167654</td>\n",
       "      <td>1.297653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>02_MAN_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>ro</td>\n",
       "      <td>5175.50</td>\n",
       "      <td>241.50</td>\n",
       "      <td>520.75</td>\n",
       "      <td>62.25</td>\n",
       "      <td>0.872958</td>\n",
       "      <td>1.070357</td>\n",
       "      <td>0.107624</td>\n",
       "      <td>0.931411</td>\n",
       "      <td>0.140400</td>\n",
       "      <td>1.212211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>03_CAT_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>ro</td>\n",
       "      <td>7343.50</td>\n",
       "      <td>117.25</td>\n",
       "      <td>18.75</td>\n",
       "      <td>20.50</td>\n",
       "      <td>0.981865</td>\n",
       "      <td>1.429961</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.990825</td>\n",
       "      <td>0.231638</td>\n",
       "      <td>1.454102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>04_HELICOPTER_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>ro</td>\n",
       "      <td>12479.50</td>\n",
       "      <td>1693.00</td>\n",
       "      <td>149.75</td>\n",
       "      <td>677.75</td>\n",
       "      <td>0.877148</td>\n",
       "      <td>1.384808</td>\n",
       "      <td>0.058388</td>\n",
       "      <td>0.931245</td>\n",
       "      <td>0.423826</td>\n",
       "      <td>1.778896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>05_HEN_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>ro</td>\n",
       "      <td>11217.00</td>\n",
       "      <td>337.25</td>\n",
       "      <td>293.50</td>\n",
       "      <td>152.25</td>\n",
       "      <td>0.947438</td>\n",
       "      <td>1.240451</td>\n",
       "      <td>0.038579</td>\n",
       "      <td>0.972653</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>1.623816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>06_LION_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>ro</td>\n",
       "      <td>6572.25</td>\n",
       "      <td>381.75</td>\n",
       "      <td>101.25</td>\n",
       "      <td>444.75</td>\n",
       "      <td>0.935600</td>\n",
       "      <td>1.624855</td>\n",
       "      <td>0.078516</td>\n",
       "      <td>0.964557</td>\n",
       "      <td>0.648087</td>\n",
       "      <td>2.260732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>07_UFO_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>ro</td>\n",
       "      <td>9707.50</td>\n",
       "      <td>29.75</td>\n",
       "      <td>12.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.995641</td>\n",
       "      <td>0.997815</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.997816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.997816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>08_TREE_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>ro</td>\n",
       "      <td>8299.00</td>\n",
       "      <td>325.00</td>\n",
       "      <td>221.50</td>\n",
       "      <td>154.50</td>\n",
       "      <td>0.939278</td>\n",
       "      <td>1.311983</td>\n",
       "      <td>0.043599</td>\n",
       "      <td>0.968124</td>\n",
       "      <td>0.361192</td>\n",
       "      <td>1.690508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>09_GIRL_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>ro</td>\n",
       "      <td>10303.50</td>\n",
       "      <td>52.00</td>\n",
       "      <td>139.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.981762</td>\n",
       "      <td>1.036084</td>\n",
       "      <td>0.013954</td>\n",
       "      <td>0.990793</td>\n",
       "      <td>0.049628</td>\n",
       "      <td>1.090048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>10_DOG_f</td>\n",
       "      <td>d_i_k_q_b</td>\n",
       "      <td>rf</td>\n",
       "      <td>ro</td>\n",
       "      <td>11450.75</td>\n",
       "      <td>547.50</td>\n",
       "      <td>393.00</td>\n",
       "      <td>358.75</td>\n",
       "      <td>0.926234</td>\n",
       "      <td>1.405363</td>\n",
       "      <td>0.062655</td>\n",
       "      <td>0.960553</td>\n",
       "      <td>0.432750</td>\n",
       "      <td>1.826053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                File       data classifier balancing        TN       FP  \\\n",
       "25         01_TANK_f  d_i_k_q_b         rf        ro   8976.75   270.25   \n",
       "121         02_MAN_f  d_i_k_q_b         rf        ro   5175.50   241.50   \n",
       "217         03_CAT_f  d_i_k_q_b         rf        ro   7343.50   117.25   \n",
       "313  04_HELICOPTER_f  d_i_k_q_b         rf        ro  12479.50  1693.00   \n",
       "409         05_HEN_f  d_i_k_q_b         rf        ro  11217.00   337.25   \n",
       "505        06_LION_f  d_i_k_q_b         rf        ro   6572.25   381.75   \n",
       "601         07_UFO_f  d_i_k_q_b         rf        ro   9707.50    29.75   \n",
       "697        08_TREE_f  d_i_k_q_b         rf        ro   8299.00   325.00   \n",
       "793        09_GIRL_f  d_i_k_q_b         rf        ro  10303.50    52.00   \n",
       "889         10_DOG_f  d_i_k_q_b         rf        ro  11450.75   547.50   \n",
       "\n",
       "         FN      TP  accuracy  total f1  imb ratio  f1 (auth)  f1 (tamp)  \\\n",
       "25   432.25   70.75  0.927949  1.123273   0.054396   0.962345   0.167654   \n",
       "121  520.75   62.25  0.872958  1.070357   0.107624   0.931411   0.140400   \n",
       "217   18.75   20.50  0.981865  1.429961   0.005261   0.990825   0.231638   \n",
       "313  149.75  677.75  0.877148  1.384808   0.058388   0.931245   0.423826   \n",
       "409  293.50  152.25  0.947438  1.240451   0.038579   0.972653   0.325581   \n",
       "505  101.25  444.75  0.935600  1.624855   0.078516   0.964557   0.648087   \n",
       "601   12.75    0.00  0.995641  0.997815   0.001309   0.997816   0.000000   \n",
       "697  221.50  154.50  0.939278  1.311983   0.043599   0.968124   0.361192   \n",
       "793  139.50    5.00  0.981762  1.036084   0.013954   0.990793   0.049628   \n",
       "889  393.00  358.75  0.926234  1.405363   0.062655   0.960553   0.432750   \n",
       "\n",
       "      f1 mine  \n",
       "25   1.297653  \n",
       "121  1.212211  \n",
       "217  1.454102  \n",
       "313  1.778896  \n",
       "409  1.623816  \n",
       "505  2.260732  \n",
       "601  0.997816  \n",
       "697  1.690508  \n",
       "793  1.090048  \n",
       "889  1.826053  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So, the best selection is 'd_i_k_q_b', 'rf', '-', probabaly.\n",
    "selection = df.loc[\n",
    "             (df['balancing']=='ro') & \n",
    "             (df['classifier']=='rf') &\n",
    "             (df['data']=='d_i_k_q_b')\n",
    "            ]\n",
    "selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File          01_TANK_f02_MAN_f03_CAT_f04_HELICOPTER_f05_HEN...\n",
       "data          d_i_k_q_bd_i_k_q_bd_i_k_q_bd_i_k_q_bd_i_k_q_bd...\n",
       "classifier                                 rfrfrfrfrfrfrfrfrfrf\n",
       "balancing                                            ----------\n",
       "TN                                                      93478.8\n",
       "FP                                                      2041.75\n",
       "FN                                                       2799.5\n",
       "TP                                                         1430\n",
       "accuracy                                                9.51194\n",
       "total f1                                                12.1044\n",
       "imb ratio                                              0.464281\n",
       "f1 (auth)                                               9.74223\n",
       "f1 (tamp)                                               2.45885\n",
       "f1 mine                                                 14.6599\n",
       "dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection.sum(axis = 0, skipna = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File          01_TANK_f02_MAN_f03_CAT_f04_HELICOPTER_f05_HEN...\n",
       "data          d_i_k_q_bd_i_k_q_bd_i_k_q_bd_i_k_q_bd_i_k_q_bd...\n",
       "classifier                                 rfrfrfrfrfrfrfrfrfrf\n",
       "balancing                                  rorororororororororo\n",
       "TN                                                      91525.2\n",
       "FP                                                      3995.25\n",
       "FN                                                         2283\n",
       "TP                                                       1946.5\n",
       "accuracy                                                9.38587\n",
       "total f1                                                12.6249\n",
       "imb ratio                                              0.464281\n",
       "f1 (auth)                                               9.67032\n",
       "f1 (tamp)                                               2.78076\n",
       "f1 mine                                                 15.2318\n",
       "dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So, the best selection is 'd_i_k_q_b', 'rf', '-', probabaly.\n",
    "selection = df.loc[\n",
    "             (df['balancing']=='ro') & \n",
    "             (df['classifier']=='rf') &\n",
    "             (df['data']=='d_i_k_q_b')\n",
    "            ]\n",
    "selection\n",
    "selection.sum(axis = 0, skipna = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for key frame analysis, the best combination seems to be random forest classifier with random oversampling, and all the data that we have. Even then, the number of false positives and false negatives is quite substantial."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "1_notmnist.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
